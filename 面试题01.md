---
title: 面试题
tags: 面试题
category: 
renderNumberedHeading: true
grammar_cjkRuby: true
---
这是我昨天面试的其中3个题目

1）大数据多租户，根据你们的认识，谈谈该如何设计？
资源权限控制
资源权限控制指的是租户对大数据平台组件的使用权限的管理，对租户权限进行严密的权限控制，按照实际租户需要分配特定的使用权限。其中比较常见的是针对如HDFS、hbase、Kafka和yarn队列等一系列组件的权限控制。

业界常用的解决方案是使用 Apache Ranger 或 Apache Sentry。前置集群的多租户功能技术选型为Apache Ranger。Apache Ranger是hortonworks提供一个集中式安全管理框架，它可以对Hadoop生态的组件如Hive，Hbase进行细粒度的数据访问控制。

Ranger架构
Ranger主要由以下三个组件构成：
（1）Ranger Admin：Ranger Admin是Ranger的核心模块，它内置了一个Web管理页面，用户可以通过这个Web管理界面或者REST接口来制定安全策略。
（2）Agent Plugin：Agent Plugin是嵌入到Hadoop生态组件中的插件，它定期从Ranger Admin拉取策略并执行，同时记录操作记录以供审计。
（3）User Sync：User Sync将操作系统用户/属组（Users/Groups）的权限数据同步到Ranger的数据库中。


工作流程：

Ranger Admin是Apache Ranger和用户交互的主要界面。
当用户登录Ranger Admin时，可以针对不同的Hadoop组件制定不同的安全策略；当策略制定好并保存之后，Agent Plugin定期（默认是30秒）从Ranger Admin拉取该组件配置的所有策略，并缓存到本地。
这样，当有用户来请求Hadoop组件的数据服务时，Agent Plugin就提供鉴权服务，并将鉴权结果反馈给相应的组件，从而实现了数据服务的权限控制功能。
当用户在Ranger Admin中修改配置策略后，Agent Plugin会拉取新策略并更新；如果用户在Ranger Admin中删除了配置策略，那么Agent Plugin的鉴权服务也无法继续使用。



2）两个集群，如何把一个集群的hive表的数据处理完后，写到另外一个集群的hive表中去
	1. 迁移Hive数据至新集群，在新集群上执行
版本差异不大，使用hdfs

``` javascript

hadoop distcp -skipcrccheck -update hdfs://hadoop-master:8020/user/hive/* \
hdfs://cdh-master:8020/user/hive

#-update 如果新集群目标目录已经存在，替换差异文件，不存在则不用这个参数。
#-skipcrccheck -update 忽略crc检查，hadoop版本相同则不需要，-skipcrccheck必须与-update同时使用才能生效。
```

版本差异大，使用htfp

``` javascript
hadoop distcp -skipcrccheck -update htfp://hadoop-master:50070/user/hive/* \
hdfs://cdh-master:8020/user/hive

#因为从Hadoop2.6迁移到Hadoop3.0版本，使用hftp方式。
#源集群的格式是 hftp://<dfs.http.address>/<path> ，默认设置dfs.http.address是 <namenode>:50070。
#新的webhdfs协议代替了hftp后，源地址和目标地址都可以使用http协议webhdfs，可以完全兼容 。

hadoop distcp -skipcrccheck -update webhdfs://hadoop-master:50070/user/hive/* \
webhdfs://cdh-master:50070/user/hive
```
注意DistCp使用绝对路径进行操作
拷贝完成后，建议生成源端和目的端文件的列表，并交叉检查，来确认拷贝真正成功。 因为DistCp使用Map/Reduce和文件系统API进行操作，所以这三者或它们之间有任何问题 都会影响拷贝操作。
	2.再使用hive命令将表和目的地的hdfs数据文件关联

参考：https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html						https://blog.51cto.com/u_15349750/3709505#2.%20%E6%8B%B7%E8%B4%9D%E5%AF%BC%E5%87%BA%E7%9A%84Hive%E6%95%B0%E6%8D%AE%E5%88%B0%E6%96%B0%E9%9B%86%E7%BE%A4
3）distcp底层源码实现 是什么样的

也是mr job
run()->execute()->createJob()
run方法
``` javascript
 /**
   * Implementation of Tool::run(). Orchestrates the copy of source file(s)
   * to target location, by:
   *  1. Creating a list of files to be copied to target.
   *  2. Launching a Map-only job to copy the files. (Delegates to execute().)
   * @param argv List of arguments passed to DistCp, from the ToolRunner.
   * @return On success, it returns 0. Else, -1.
   */
  @Override
  public int run(String[] argv) {
    if (argv.length < 1) {
      OptionsParser.usage();
      return DistCpConstants.INVALID_ARGUMENT;
    }
    
    try {
      context = new DistCpContext(OptionsParser.parse(argv));
      checkSplitLargeFile();
      setTargetPathExists();
      LOG.info("Input Options: " + context);
    } catch (Throwable e) {
      LOG.error("Invalid arguments: ", e);
      System.err.println("Invalid arguments: " + e.getMessage());
      OptionsParser.usage();      
      return DistCpConstants.INVALID_ARGUMENT;
    }
    
    try {
      execute();
    } catch (InvalidInputException e) {
      LOG.error("Invalid input: ", e);
      return DistCpConstants.INVALID_ARGUMENT;
    } catch (DuplicateFileException e) {
      LOG.error("Duplicate files in input path: ", e);
      return DistCpConstants.DUPLICATE_INPUT;
    } catch (AclsNotSupportedException e) {
      LOG.error("ACLs not supported on at least one file system: ", e);
      return DistCpConstants.ACLS_NOT_SUPPORTED;
    } catch (XAttrsNotSupportedException e) {
      LOG.error("XAttrs not supported on at least one file system: ", e);
      return DistCpConstants.XATTRS_NOT_SUPPORTED;
    } catch (Exception e) {
      LOG.error("Exception encountered ", e);
      return DistCpConstants.UNKNOWN_ERROR;
    }
    return DistCpConstants.SUCCESS;
  }
```

execute方法
``` javascript
  /**
   * Implements the core-execution. Creates the file-list for copy,
   * and launches the Hadoop-job, to do the copy.
   * @return Job handle
   * @throws Exception
   */
  public Job execute() throws Exception {
    Preconditions.checkState(context != null,
        "The DistCpContext should have been created before running DistCp!");
    Job job = createAndSubmitJob();

    if (context.shouldBlock()) {
      waitForJobCompletion(job);
    }
    return job;
  }
```

createJob方法
``` javascript
/**
   * Create Job object for submitting it, with all the configuration
   *
   * @return Reference to job object.
   * @throws IOException - Exception if any
   */
  private Job createJob() throws IOException {
    String jobName = "distcp";
    String userChosenName = getConf().get(JobContext.JOB_NAME);
    if (userChosenName != null)
      jobName += ": " + userChosenName;
    Job job = Job.getInstance(getConf());
    job.setJobName(jobName);
    job.setInputFormatClass(DistCpUtils.getStrategy(getConf(), context));
    job.setJarByClass(CopyMapper.class);
    configureOutputFormat(job);

    job.setMapperClass(CopyMapper.class);
    job.setNumReduceTasks(0);
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(Text.class);
    job.setOutputFormatClass(CopyOutputFormat.class);
    job.getConfiguration().set(JobContext.MAP_SPECULATIVE, "false");
    job.getConfiguration().set(JobContext.NUM_MAPS,
                  String.valueOf(context.getMaxMaps()));

    context.appendToConf(job.getConfiguration());
    return job;
  }
```


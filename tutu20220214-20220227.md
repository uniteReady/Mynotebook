---
title: tutu20220214-20220227
tags: 作业
category: /小书匠/日记/2022-02
renderNumberedHeading: true
grammar_cjkRuby: true
---

20220214-20220227
Q1：谈谈你对Kafka容错机制的理解，从如下角度出发：
➢ 如何保证宕机时数据不丢

``` javascript
	只有当消息被写入分区的所有副本时，它才被认为是“已提交”的。生产者可以选择接收不同类型的确认，比如在消息被完全提交时的确认、在消息被写入分区首领时的确认，或者在消息被发送到网络时的确认。只要还有一个副本是活跃的，那么已经提交的信息就不会丢失
```

➢ 多副本冗余的高可用机制
	

``` javascript
	通过集群的多副本机制。每个partition不再只有一个，而是有一个leader和多个replica，生产者根据消息的topic和key值，确定了消息要发往哪个partition之后），会找到partition对应的leader，然后将消息发给leader，leader负责消息的写入，并与其余的replica进行同步。一旦某一个partition的leader挂掉了，那么只需提拔一个replica出来，让它成为leader就ok了，系统依旧可以正常运行
```

➢ 多副本之间数据如何同步

``` javascript
	在Kafka中发生复制时确保partition的预写式日志有序地写到其他节点上。N个replicas中。其中一个replica为leader，其他都为follower，leader处理partition的所有读写请求，与此同时，follower会被动定期地去复制leader上的数据。
	Kafka确保从同步副本列表中选举一个副本为leader，或者说follower追赶leader数据。leader负责维护和跟踪ISR中所有follower滞后的状态。当producer发送一条消息到broker后，leader写入消息并复制到所有follower。消息提交之后才被成功复制到所有的同步副本。Follower只复制按顺序同步Leader的消息，而且只有ISR中所有节点都同步成功的消息才算写入成功，所以消息写入延迟受最慢同步副本的限制。在日志复制协议（Log Replication Algorithm）设计上需要需要快速检测慢副本并把其从ISR中剔除。

➢ acks参数
``` javascript
对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没有必要等ISR中的follower全部接收成功。所以Kafka提供了三种可靠性级别，用户可以根据对可靠性和延迟的要求进行权衡。acks

0： producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没写入磁盘就已经返回，当broker故障时可能丢失数据；
1： producer等待leader的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据；
-1（all）：producer等待broker的ack，partition的leader和ISR里的follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成重复数据。（极端情况下也有可能丢数据：ISR中只有一个Leader时，相当于1的情况）。
```
➢ ISR的意义

``` javascript
在Kafka中，每个Partition只有Leader能接收Producer的写入，并向Consumer提供消息消费服务，Follower只复制按顺序同步Leader的消息，而且只有ISR中所有节点都同步成功的消息才算写入成功，所以消息写入延迟受最慢同步副本的限制。在日志复制协议（Log Replication Algorithm）设计上需要需要快速检测慢副本并把其从ISR中剔除。
```

➢ acks=all就代表数据一定不会丢失吗

``` javascript
不是，极端情况，ISR就leader，leader接受message 发送ack后就挂了，数据就丢了。
```

Q2：Kafka文件存储机制

``` javascript
一个partition被切割成多个相同大小的segment
	
	由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引的机制，将每个partition分为多个segment
		xxx.index  offset和物理位移pos
			是索引文件，维护该partition的message对应的offset，对应的物理地址 物理偏移量 字节byte
			是【稀疏】维护   换句话说 不是每个message都被维护到index 
			offset 该partition下的全局  是从0开始 绝对offset
			正是有了这个index文件，才能对任一数据写入和查看拥有O(1)的复杂度
			index文件的粒度可以通过参数log.index.interval.bytes来控制，默认是是每过4096字节记录一条index
		xxx.log  数据
			存储message和对应offset
	segment由log.segment.bytes（默认1,073,741,824‬b（1GB））决定，控制每个segment的大小，也可通过log.segment.ms控制，指定多长时间后日志片段会被关闭。					
	这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号。每个partition中的每个消息message 都是有一个连续的序列号来标识 ，用于 partition的唯一标识
segment(log和index文件等)如何命名
	每个 LogSegment 都有一个基准偏移量，用来表示当前 LogSegment 中第一条消息的 offset。偏移量是一个 64位的长整形数，固定是20位数字，长度未达到，用 0 进行填补
		index和log文件以当前segment的第一条消息的offset命名，因此第一个index和log文件文件名称 必然是00000000000000000000开头
		
	
```

Q3：Kafka分区分配策略：Range、RoundRobin策略源码分析梳理清楚partition会被哪个消费者组消费
Q4：Kafka为什么吞吐量高？从Zero-Copy角度详细阐述
